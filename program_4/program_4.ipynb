{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22. 28.]\n",
      " [49. 64.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# Creates a graph.\n",
    "a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "c = tf.matmul(a, b)\n",
    "# Creates a session with log_device_placement set to True.\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "# Runs the op.\n",
    "print(sess.run(c))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Data Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_dir = os.path.join('ECEN489Py4Data', 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ImageDataGenerator implements functions useful for input image scaling and augmentation -- you may want more!\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2744 images belonging to 8 classes.\n",
      "Found 929 images belonging to 8 classes.\n",
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        os.path.join(data_dir, 'train'),\n",
    "        target_size=(32, 32),\n",
    "        color_mode='rgb',\n",
    "        batch_size=1,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True,\n",
    "        seed=1953)\n",
    "\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "        os.path.join(data_dir, 'validation'),\n",
    "        target_size=(32, 32),\n",
    "        color_mode='rgb',\n",
    "        batch_size=1,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False, #don't shuffle or label results will be all wrong\n",
    "        seed=1953)\n",
    "\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    os.path.join(data_dir, 'test'),\n",
    "    target_size=(32, 32),\n",
    "    color_mode='rgb',\n",
    "    batch_size=1,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False, #don't shuffle or label results will be all wrong\n",
    "    seed=1953)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN From Nowka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# neural network model\n",
    "# you may want to vary these parameters, etc\n",
    "\n",
    "num_classes = 8 # fixed by the number of classes of signs that we gave you. Dont change\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',input_shape = (32, 32, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 4104      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 8)                 0         \n",
      "=================================================================\n",
      "Total params: 2,121,160\n",
      "Trainable params: 2,121,160\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = 'Adam', # may want to try others\n",
    "              metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/4\n",
      "2744/2744 [==============================] - 19s 7ms/step - loss: 0.4474 - acc: 0.8721 - val_loss: 0.1305 - val_acc: 0.9612\n",
      "Epoch 2/4\n",
      "2744/2744 [==============================] - 18s 6ms/step - loss: 0.1418 - acc: 0.9566 - val_loss: 0.1626 - val_acc: 0.9483\n",
      "Epoch 3/4\n",
      "2744/2744 [==============================] - 18s 6ms/step - loss: 0.1110 - acc: 0.9730 - val_loss: 0.1279 - val_acc: 0.9666\n",
      "Epoch 4/4\n",
      "2744/2744 [==============================] - 18s 6ms/step - loss: 0.0645 - acc: 0.9840 - val_loss: 0.0860 - val_acc: 0.9839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f153d7cbb38>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=4 # may need to increase if not seeing low enough losses\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[ 41  10   1   0   0   0   0   0]\n",
      " [  0  38  11   0   0   0   0   1]\n",
      " [  0   0 186  14   0   0   0   0]\n",
      " [  0   0   0 140  11   0   3   0]\n",
      " [  0   0   0   0   6  11   0   0]\n",
      " [  0   0   0   0   0  36  11   0]\n",
      " [  0   0   3   2   0   0 371  11]\n",
      " [ 11   0   0   0   0   0   2   9]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       merge       0.79      0.79      0.79        52\n",
      "       yield       0.79      0.76      0.78        50\n",
      "   keepRight       0.93      0.93      0.93       200\n",
      "speedLimit25       0.90      0.91      0.90       154\n",
      "  pedestrian       0.35      0.35      0.35        17\n",
      "speedLimit35       0.77      0.77      0.77        47\n",
      "        stop       0.96      0.96      0.96       387\n",
      " signalAhead       0.43      0.41      0.42        22\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       929\n",
      "   macro avg       0.74      0.73      0.74       929\n",
      "weighted avg       0.89      0.89      0.89       929\n",
      "\n",
      "F1 score (using average='micro')\n",
      "0.8902045209903121\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict_generator(valid_generator, steps=STEP_SIZE_VALID)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(valid_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "print(classification_report(valid_generator.classes, y_pred, target_names=valid_generator.class_indices))\n",
    "print(\"F1 score (using average='micro')\")\n",
    "print(f1_score(y_true=valid_generator.classes, y_pred=y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USE CELLS BELOW TO COMPLETE THE EXERCISE WITH THE TEST SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "# Y_pred = model.predict_generator(test_generator, steps=STEP_SIZE_TEST)\n",
    "# y_pred = np.argmax(Y_pred, axis=1)\n",
    "# print('Confusion Matrix')\n",
    "# print(confusion_matrix(test_generator.classes, y_pred))\n",
    "# print('Classification Report')\n",
    "# print(classification_report(test_generator.classes, y_pred, target_names=train_generator.class_indices))\n",
    "# print(\"F1 score (using average='micro')\")\n",
    "# print(f1_score(y_true=test_generator.classes, y_pred=y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "929\n",
      "929\n"
     ]
    }
   ],
   "source": [
    "#This cell dumps out a file of which files were incorrectly predicted\n",
    "#so you can see if you need more features, more training samples, etc\n",
    "predicted_class_indices=np.argmax(Y_pred,axis=1)\n",
    "labels = (train_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "# NOTE/TODO: Change this to test_generator later.\n",
    "filenames=valid_generator.filenames\n",
    "# filenames=test_generator.filenames\n",
    "print(len(filenames))\n",
    "print(len(predictions))\n",
    "results=pd.DataFrame({\"Filename\":filenames,\n",
    "                      \"Predictions\":predictions})\n",
    "results.to_csv(\"results.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
